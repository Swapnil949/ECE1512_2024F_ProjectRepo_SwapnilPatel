{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import ViTForImageClassification, AutoModelForImageClassification\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "from torch.profiler import profile, record_function, ProfilerActivity\n",
    "from tqdm.auto import tqdm\n",
    "from torch.utils.data import Subset\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:164: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, xz, conv1d_weight, conv1d_bias, x_proj_weight, delta_proj_weight,\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/ops/selective_scan_interface.py:240: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout):\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:986: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/ops/triton/layer_norm.py:1045: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/distributed/tensor_parallel.py:26: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, x, weight, bias, process_group=None, sequence_parallel=True):\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/distributed/tensor_parallel.py:62: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, grad_output):\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_combined.py:758: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(ctx, zxbcdt, conv1d_weight, conv1d_bias, dt_bias, A, D, chunk_size, initial_states=None, seq_idx=None, dt_limit=(0.0, float(\"inf\")), return_final_states=False, activation=\"silu\",\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/mamba_ssm/ops/triton/ssd_combined.py:836: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n",
      "/root/miniconda3/envs/mamba/lib/python3.10/site-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n",
      "Some weights of MambaVisionModelForImageClassification were not initialized from the model checkpoint at Swapnil949/mambavision-finetuned-cifar100 and are newly initialized because the shapes did not match:\n",
      "- model.head.bias: found shape torch.Size([100]) in the checkpoint and torch.Size([1000]) in the model instantiated\n",
      "- model.head.weight: found shape torch.Size([100, 1024]) in the checkpoint and torch.Size([1000, 1024]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "vit_model = ViTForImageClassification.from_pretrained(\n",
    "    \"Swapnil949/vit-finetuned-cifar100\")\n",
    "mamba_model = AutoModelForImageClassification.from_pretrained(\n",
    "    \"Swapnil949/mambavision-finetuned-cifar100\",\n",
    "    ignore_mismatched_sizes=True,\n",
    "    trust_remote_code=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trans = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "test_dataset = datasets.CIFAR100(root=\"./data\", train=False, download=True, transform=trans)\n",
    "\n",
    "# Choose a fraction (e.g., 10%) of the data\n",
    "fraction = 0.001\n",
    "num_samples = int(len(test_dataset) * fraction)\n",
    "indices = np.random.choice(len(test_dataset), num_samples, replace=False)  # Randomly select indices\n",
    "\n",
    "# Create a subset of the dataset\n",
    "small_test_dataset = Subset(test_dataset, indices)\n",
    "\n",
    "# Create a DataLoader for the smaller dataset\n",
    "test_loader = DataLoader(small_test_dataset, batch_size=1, shuffle=False)                         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Profiling ViT model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     223.753ms        89.73%     223.753ms     223.753ms             1  \n",
      "                                        model_inference        29.10%      68.800ms       100.00%     236.385ms     236.385ms       0.000us         0.00%      25.611ms      25.611ms             1  \n",
      "                                           aten::linear         3.10%       7.329ms        23.91%      56.512ms      77.414us       0.000us         0.00%      18.913ms      25.908us           730  \n",
      "                                            aten::addmm        10.73%      25.354ms        16.35%      38.660ms      52.959us      18.913ms         7.58%      18.913ms      25.908us           730  \n",
      "                        ampere_sgemm_64x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us      12.949ms         5.19%      12.949ms      21.582us           600  \n",
      "                                 ampere_sgemm_128x32_tn         0.00%       0.000us         0.00%       0.000us       0.000us       5.696ms         2.28%       5.696ms      47.463us           120  \n",
      "                     aten::scaled_dot_product_attention         0.88%       2.089ms         5.44%      12.862ms     107.187us       0.000us         0.00%       4.409ms      36.742us           120  \n",
      "          aten::_scaled_dot_product_efficient_attention         0.68%       1.616ms         4.56%      10.773ms      89.778us       0.000us         0.00%       4.409ms      36.742us           120  \n",
      "                     aten::_efficient_attention_forward         1.26%       2.971ms         3.13%       7.394ms      61.620us       4.409ms         1.77%       4.409ms      36.742us           120  \n",
      "fmha_cutlassF_f32_aligned_64x64_rf_sm80(PyTorchMemEf...         0.00%       0.000us         0.00%       0.000us       0.000us       4.409ms         1.77%       4.409ms      36.742us           120  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 236.392ms\n",
      "Self CUDA time total: 249.365ms\n",
      "\n",
      "Profiling MambaVision model...\n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "                                        model_inference         0.00%       0.000us         0.00%       0.000us       0.000us     257.278ms        90.82%     257.278ms     257.278ms             1  \n",
      "                                        model_inference        29.44%      76.790ms       100.00%     260.801ms     260.801ms       0.000us         0.00%      26.004ms      26.004ms             1  \n",
      "                                           aten::linear         1.55%       4.050ms        20.38%      53.163ms      69.043us       0.000us         0.00%      12.983ms      16.861us           770  \n",
      "                                            aten::addmm         6.80%      17.737ms        12.33%      32.169ms      60.697us      11.004ms         3.88%      11.004ms      20.762us           530  \n",
      "                                      aten::convolution         0.60%       1.574ms        10.48%      27.342ms      82.856us       0.000us         0.00%       5.496ms      16.653us           330  \n",
      "                                     aten::_convolution         1.30%       3.401ms         9.88%      25.768ms      78.086us       0.000us         0.00%       5.496ms      16.653us           330  \n",
      "                       ampere_sgemm_128x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       4.961ms         1.75%       4.961ms      24.807us           200  \n",
      "                                           aten::conv2d         0.21%     559.618us         5.76%      15.018ms      88.338us       0.000us         0.00%       4.839ms      28.467us           170  \n",
      "                                aten::cudnn_convolution         2.14%       5.578ms         3.84%      10.017ms      58.925us       4.569ms         1.61%       4.569ms      26.874us           170  \n",
      "                        ampere_sgemm_64x32_sliced1x4_tn         0.00%       0.000us         0.00%       0.000us       0.000us       4.259ms         1.50%       4.259ms      15.775us           270  \n",
      "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
      "Self CPU time total: 260.810ms\n",
      "Self CUDA time total: 283.282ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Profile the inference for both models\n",
    "for model_name, model in zip([\"ViT\", \"MambaVision\"], [vit_model, mamba_model]):\n",
    "    print(f\"Profiling {model_name} model...\")\n",
    "    model.eval()\n",
    "    model.cuda()\n",
    "\n",
    "    with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA], record_shapes=True) as prof:\n",
    "        with record_function(\"model_inference\"):\n",
    "            for inputs, _ in test_loader:\n",
    "                inputs = inputs.cuda()\n",
    "                with torch.no_grad():\n",
    "                    model(inputs)\n",
    "\n",
    "    # Print profiling results\n",
    "    print(prof.key_averages().table(sort_by=\"cuda_time_total\", row_limit=10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mamba",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
