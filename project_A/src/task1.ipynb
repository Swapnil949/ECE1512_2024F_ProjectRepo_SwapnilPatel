{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.utils import save_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    properties = torch.cuda.get_device_properties(0)\n",
    "    compute_capability = f\"{properties.major}.{properties.minor}\"\n",
    "    total_memory = properties.total_memory / 1024**3\n",
    "\n",
    "    print(f\"CUDA Device: {device_name}\")\n",
    "    print(f\"CUDA Compute Capability: {compute_capability}\")\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# load MNIST dataset from utils\n",
    "from utils import get_dataset\n",
    "\n",
    "(\n",
    "    channel,\n",
    "    im_size,\n",
    "    num_classes,\n",
    "    class_names,\n",
    "    mean,\n",
    "    std,\n",
    "    train_MNIST_dataset,\n",
    "    test_MNIST_dataset,\n",
    "    test_MNIST_dataloader,\n",
    "    train_MNIST_dataloader,\n",
    ") = get_dataset(\"MNIST\", \"../datasets\")\n",
    "\n",
    "# visualize 10 classes of MNIST (2 by 5)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(\n",
    "        train_MNIST_dataset.data[train_MNIST_dataset.targets == i][0], cmap=\"gray\"\n",
    "    )\n",
    "    ax.set_title(f\"{i}\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "from utils import get_network\n",
    "\n",
    "ConvNet3 = get_network('ConvNetD3', channel, num_classes, im_size)\n",
    "print(ConvNet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "n_epochs = 4\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet3.parameters(), lr=lr)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    ConvNet3.train()\n",
    "    running_loss = 0.0\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(train_MNIST_dataloader, 0),\n",
    "        total=len(train_MNIST_dataloader),\n",
    "        desc=f\"Epoch {epoch+1}\",\n",
    "    )\n",
    "\n",
    "    total_iterations = len(train_MNIST_dataloader)\n",
    "    for i, data in enumerate(train_MNIST_dataloader, 0):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = ConvNet3(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        percentage_complete = (i + 1) / total_iterations * 100\n",
    "        progress_bar.set_postfix(loss=running_loss / (i + 1))\n",
    "        progress_bar.update(1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# report classification accuracy for test dataset\n",
    "ConvNet3.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in test_MNIST_dataloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = ConvNet3(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Distillation using Attention matching Algorithm\n",
    "\n",
    "Portions of code used for attention matcching algorithm is taken from the following repository:\n",
    "\n",
    "https://github.com/DataDistillation/DataDAM/\n",
    "\n",
    "A. Sajedi, S. Khaki, E. Amjadian, L. Z. Liu, Y. A. Lawryshyn, and K. N. Plataniotis, DataDAM: Efficient Dataset Distillation with Attention Matching. 2023. [Online]. Available: https://arxiv.org/abs/2310.00093 \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# learn synthetic dataset using Attention matching algorithm\n",
    "\n",
    "\"\"\" organize the real dataset \"\"\"\n",
    "images_all = []\n",
    "labels_all = []\n",
    "indices_class = [[] for c in range(num_classes)]\n",
    "\n",
    "images_all = [\n",
    "    torch.unsqueeze(train_MNIST_dataset[i][0], dim=0)\n",
    "    for i in range(len(train_MNIST_dataset))\n",
    "]\n",
    "labels_all = [train_MNIST_dataset[i][1] for i in range(len(train_MNIST_dataset))]\n",
    "\n",
    "for i, lab in enumerate(labels_all):\n",
    "    indices_class[lab].append(i)\n",
    "images_all = torch.cat(images_all, dim=0).to(device)\n",
    "labels_all = torch.tensor(labels_all, dtype=torch.long, device=device)\n",
    "\n",
    "def get_images(c, n):  # get random n images from class c\n",
    "    idx_shuffle = np.random.permutation(indices_class[c])[:n]\n",
    "    return images_all[idx_shuffle]\n",
    "\n",
    "\n",
    "for c in range(num_classes):\n",
    "    print(\"class\\t%d:\\t%d real images\" % (c, len(indices_class[c])))\n",
    "    \n",
    "for ch in range(channel):\n",
    "    print(\n",
    "        \"real images channel %d, mean = %.4f, std = %.4f\"\n",
    "        % (ch, torch.mean(images_all[:, ch]), torch.std(images_all[:, ch]))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ipc = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Initialize the synthetic dataset \"\"\"\n",
    "images_syn = torch.randn(\n",
    "    size=(num_classes*ipc, channel, im_size[0], im_size[1]),\n",
    "    dtype=torch.float,\n",
    "    requires_grad=True,\n",
    "    device=device,\n",
    ")\n",
    "\n",
    "# Convert list of numpy arrays to a single numpy array\n",
    "labels_array = np.array([np.ones(ipc) * c for c in range(num_classes)])\n",
    "\n",
    "# Convert numpy array to tensor\n",
    "labels_syn = torch.tensor(\n",
    "    labels_array,\n",
    "    dtype=torch.long,\n",
    "    requires_grad=False,\n",
    "    device=device,\n",
    ").view(-1)\n",
    "\n",
    "# Initialize synthetic dataset using real images\n",
    "for c in range(num_classes):\n",
    "    real_images = get_images(c, ipc)\n",
    "    images_syn.data[c*ipc:(c+1)*ipc] = real_images.data\n",
    "\n",
    "# print details of synthetic dataset, size and all\n",
    "print(images_syn.size())\n",
    "print(labels_syn.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# plot all images_syn\n",
    "fig, axes = plt.subplots(num_classes, ipc, figsize=(ipc, num_classes))\n",
    "for i in range(num_classes):\n",
    "    for j in range(ipc):\n",
    "        axes[i, j].imshow(images_syn[i * ipc + j][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "        axes[i, j].axis(\"off\")\n",
    "#save the plot\n",
    "plt.savefig(\"images_syn.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Train the synthetic dataset using Attention Matching Algorithm \"\"\"\n",
    "from utils import get_attention, TensorDataset, epoch\n",
    "import copy\n",
    "\n",
    "\n",
    "def learn_syn_dataset(\n",
    "    channel,\n",
    "    num_classes,\n",
    "    im_size,\n",
    "    images_syn,\n",
    "    ipc,\n",
    "    K=100,\n",
    "    iterations=10,\n",
    "    lr_img=0.01,\n",
    "    minibatch_size=256,\n",
    "    task_balance=0.01,\n",
    "    batch_real=128,\n",
    "    batch_train=128,\n",
    "    zeta_theta=50\n",
    "):\n",
    "    optimizer_img = torch.optim.SGD([images_syn, ], lr_img, momentum=0.5) # optimizer_img for synthetic data\n",
    "    optimizer_img.zero_grad()\n",
    "    criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "    for k in range(K):\n",
    "        net = get_network('ConvNetD3', channel, num_classes, im_size).to(device)\n",
    "        net.train() \n",
    "        for param in list(net.parameters()):\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        # Optimizer for the model\n",
    "        optimizer_net = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "        optimizer_net.zero_grad()\n",
    "        \n",
    "        activations = {}\n",
    "        def getActivation(name):\n",
    "            def hook_func(m, inp, op):\n",
    "                activations[name] = op.clone()\n",
    "            return hook_func\n",
    "\n",
    "        ''' Defining the Refresh Function to store Activations and reset Collection '''\n",
    "        def refreshActivations(activations):\n",
    "            model_set_activations = [] # Jagged Tensor Creation\n",
    "            for i in activations.keys():\n",
    "                model_set_activations.append(activations[i])\n",
    "            activations = {}\n",
    "            return activations, model_set_activations\n",
    "\n",
    "        ''' Defining the Delete Hook Function to collect Remove Hooks '''\n",
    "        def delete_hooks(hooks):\n",
    "            for i in hooks:\n",
    "                i.remove()\n",
    "            return\n",
    "                    \n",
    "        def attach_hooks(net):\n",
    "            hooks = []\n",
    "            base = net.module if torch.cuda.device_count() > 1 else net\n",
    "            for module in (base.features.named_modules()):\n",
    "                if isinstance(module[1], nn.ReLU):\n",
    "                    # Hook the Ouptus of a ReLU Layer\n",
    "                    hooks.append(base.features[int(module[0])].register_forward_hook(getActivation('ReLU_'+str(len(hooks))),))\n",
    "            return hooks\n",
    "        \n",
    "        for it in range(iterations+1) :\n",
    "            ''' visualize and save '''\n",
    "            save_name = f\"images_syn_{it}.png\"\n",
    "            image_syn_vis = copy.deepcopy(images_syn.detach().cpu())\n",
    "            for ch in range(channel):\n",
    "                image_syn_vis[:, ch] = image_syn_vis[:, ch]  * std[ch] + mean[ch]\n",
    "            image_syn_vis[image_syn_vis<0] = 0.0\n",
    "            image_syn_vis[image_syn_vis>1] = 1.0\n",
    "            save_image(image_syn_vis, save_name, nrow=ipc) # Trying normalize = True/False may get better visual effects.\n",
    "\n",
    "\n",
    "            \n",
    "            loss_avg = 0\n",
    "            def error(real, syn, err_type=\"MSE\"):          \n",
    "                if(err_type == \"MSE\"):\n",
    "                    err = torch.sum((torch.mean(real, dim=0) - torch.mean(syn, dim=0))**2)\n",
    "                            \n",
    "                elif (err_type == \"MAE\"):\n",
    "                    err = torch.sum(torch.abs(torch.mean(real, dim=0) - torch.mean(syn, dim=0)))\n",
    "                                \n",
    "                elif (err_type == \"ANG\"):\n",
    "                    rl = torch.mean(real, dim=0) \n",
    "                    sy = torch.mean(syn, dim=0)\n",
    "                    num = torch.matmul(rl, sy)\n",
    "                    denom = (torch.sum(rl**2)**0.5) * (torch.sum(sy**2)**0.5)\n",
    "                    err = torch.acos(num/denom)\n",
    "                                \n",
    "                elif (err_type == \"MSE_B\"):\n",
    "                    err = torch.sum((torch.mean(real.reshape(num_classes, batch_real, -1), dim=1).cpu() - torch.mean(syn.cpu().reshape(num_classes, ipc, -1), dim=1))**2)\n",
    "                elif (err_type == \"MAE_B\"):\n",
    "                    err = torch.sum(torch.abs(torch.mean(real.reshape(num_classes, batch_real, -1), dim=1).cpu() - torch.mean(syn.reshape(num_classes, ipc, -1).cpu(), dim=1)))\n",
    "                elif (err_type == \"ANG_B\"):\n",
    "                    rl = torch.mean(real.reshape(num_classes, batch_real, -1), dim=1).cpu()\n",
    "                    sy = torch.mean(syn.reshape(num_classes, ipc, -1), dim=1)\n",
    "                                \n",
    "                    denom = (torch.sum(rl**2)**0.5).cpu() * (torch.sum(sy**2)**0.5).cpu()\n",
    "                    num = rl.cpu() * sy.cpu()\n",
    "                    err = torch.sum(torch.acos(num/denom))\n",
    "                return err\n",
    "            \n",
    "            # update the synthetic dataset\n",
    "            loss = torch.tensor(0.0, device=device)\n",
    "            mid_loss = 0\n",
    "            out_loss = 0\n",
    "            \n",
    "            images_real_all = []\n",
    "            images_syn_all = []\n",
    "            \n",
    "            for c in range(num_classes):\n",
    "                img_real = get_images(c, ipc)\n",
    "                img_syn = images_syn[c * ipc : (c + 1) * ipc].reshape(ipc, channel, im_size[0], im_size[1])\n",
    "                \n",
    "                images_real_all.append(img_real)\n",
    "                images_syn_all.append(img_syn)\n",
    "                \n",
    "            images_real_all = torch.cat(images_real_all, dim=0)    \n",
    "            images_syn_all = torch.cat(images_syn_all, dim=0)\n",
    "            \n",
    "            hooks = attach_hooks(net)\n",
    "            outputs_real = net(images_real_all)[0].detach()\n",
    "            activations, orig_model_set_activations = refreshActivations(activations)\n",
    "            \n",
    "            output_syn = net(images_syn_all)[0]\n",
    "            activations, syn_model_set_activations = refreshActivations(activations)\n",
    "            delete_hooks(hooks)\n",
    "            \n",
    "            length_of_network = len(orig_model_set_activations)\n",
    "            \n",
    "            for layer in range(length_of_network - 1):\n",
    "                real_attentions = get_attention(orig_model_set_activations[layer], param=1, exp=1, norm='l2')\n",
    "                syn_attentions = get_attention(syn_model_set_activations[layer], param=1, exp=1, norm='l2')\n",
    "                \n",
    "                tl = 100*error(real_attentions, syn_attentions, err_type=\"MSE\")\n",
    "                loss += tl\n",
    "                mid_loss += tl\n",
    "                \n",
    "            output_loss = 100*task_balance*error(outputs_real, output_syn, err_type=\"MSE\")\n",
    "            \n",
    "            loss += output_loss\n",
    "            out_loss += output_loss\n",
    "            \n",
    "            optimizer_img.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer_img.step()\n",
    "            loss_avg += loss.item()\n",
    "            torch.cuda.empty_cache()\n",
    "        \n",
    "            # Prepare synthetic dataset and dataloader\n",
    "            image_syn_train, label_syn_train = copy.deepcopy(images_syn.detach()), copy.deepcopy(labels_syn.detach())\n",
    "            dst_syn_train = TensorDataset(image_syn_train, label_syn_train)\n",
    "            trainloader = torch.utils.data.DataLoader(dst_syn_train, batch_size=batch_train, shuffle=True, num_workers=0)\n",
    "            \n",
    "            # update network using synthetic dataset\n",
    "            for steps in range(zeta_theta):\n",
    "                epoch('train', trainloader, net, optimizer_net, criterion, device)\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "        print(f\"Loss: {loss_avg:.4f}, Output Loss: {out_loss:.4f}, Mid Loss: {mid_loss:.4f}\")\n",
    "        \n",
    "            \n",
    "learn_syn_dataset(\n",
    "    channel,\n",
    "    num_classes,\n",
    "    im_size,\n",
    "    images_syn,\n",
    "    ipc = 10,\n",
    "    iterations=10,\n",
    "    minibatch_size=256,\n",
    "    task_balance=0.01,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# plot all images_syn\n",
    "fig, axes = plt.subplots(num_classes, ipc, figsize=(ipc, num_classes))\n",
    "for i in range(num_classes):\n",
    "    for j in range(ipc):\n",
    "        axes[i, j].imshow(images_syn[i * ipc + j][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "        axes[i, j].axis(\"off\")\n",
    "        \n",
    "#save the plot\n",
    "plt.savefig(\"images_syn2.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\" Train the synthetic dataset using Attention Matching Algorithm \"\"\"\n",
    "from utils import get_attention\n",
    "\n",
    "optimizer_img = torch.optim.SGD([images_syn], lr=0.1, momentum=0.9)\n",
    "optimizer_img.zero_grad()\n",
    "\n",
    "loss = torch.tensor(0.0, device=device)\n",
    "\n",
    "images_real_all = []\n",
    "images_syn_all = []\n",
    "\n",
    "for c in range(num_classes):\n",
    "    img_real = get_images(c, minibatch_size)\n",
    "    img_sync = images_syn[c * imgs_per_class : (c + 1) * imgs_per_class].reshape(\n",
    "        (imgs_per_class, channel, im_size[0], im_size[1])\n",
    "    )\n",
    "\n",
    "    images_real_all.append(img_real)\n",
    "    images_syn_all.append(img_sync)\n",
    "\n",
    "images_real_all = torch.cat(images_real_all, dim=0)\n",
    "images_syn_all = torch.cat(images_syn_all, dim=0)\n",
    "\n",
    "hooks = attach_hooks(ConvNet3)\n",
    "output_real = ConvNet3(images_real_all).detach()\n",
    "activations, original_model_set_activations = refreshActivations(activations)\n",
    "\n",
    "\n",
    "output_syn = ConvNet3(images_syn_all).detach()\n",
    "activations, synthetic_model_set_activations = refreshActivations(activations)\n",
    "delete_hooks(hooks)\n",
    "\n",
    "print(\"output_real\", output_real.size())\n",
    "print(\"output_syn\", output_syn.size())\n",
    "\n",
    "length_of_network = len(original_model_set_activations)\n",
    "for i in range(length_of_network):\n",
    "    real_attention = get_attention(original_model_set_activations[i].detach(), param=1, exp=1, norm='l2')\n",
    "    syn_attention = get_attention(synthetic_model_set_activations[i].detach(), param=1, exp=1, norm='l2')\n",
    "\n",
    "    tl = 100*error(real_attention, syn_attention, err_type=\"MSE\")\n",
    "    loss += tl\n",
    "\n",
    "output_loss = 100*task_balance*error(output_real, output_syn, err_type=\"MSE\")\n",
    "loss += output_loss\n",
    "\n",
    "optimizer_img.zero_grad()\n",
    "loss.backward()\n",
    "optimizer_img.step()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# display output_syn images\n",
    "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(output_syn[i][0].cpu().detach().numpy(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# load MHIST dataset from MHISTDataset class\n",
    "import MHISTDataset\n",
    "\n",
    "train_MHIST_dataset = MHISTDataset.MHISTDataset('../mhist_dataset/images-split/train', transform=None)\n",
    "test_MNIST_dataset = MHISTDataset.MHISTDataset('../mhist_dataset/images-split/test', transform=None)\n",
    "\n",
    "# find train_MHIST_dataset with \"HP\" label, train_MHHIST_dataset[i][2]\n",
    "HP_indices = [i for i in range(len(train_MHIST_dataset)) if train_MHIST_dataset[i][2] == 'HP']\n",
    "SSA_indices = [i for i in range(len(train_MHIST_dataset)) if train_MHIST_dataset[i][2] == 'SSA']\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "axes[0].imshow(train_MHIST_dataset[HP_indices[0]][0])\n",
    "axes[0].set_title(\"HP\")\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(train_MHIST_dataset[SSA_indices[0]][0])\n",
    "axes[1].set_title(\"SSA\")\n",
    "axes[1].axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "bash",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
