{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from thop import profile\n",
    "from utils import get_network, get_dataset, TensorDataset\n",
    "import main_AttentionMatching\n",
    "import sys\n",
    "\n",
    "figures_dir = '../report/figures/'\n",
    "output_dir = '../output/'\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    properties = torch.cuda.get_device_properties(0)\n",
    "    compute_capability = f\"{properties.major}.{properties.minor}\"\n",
    "    total_memory = properties.total_memory / 1024**3\n",
    "\n",
    "    print(f\"CUDA Device: {device_name}\")\n",
    "    print(f\"CUDA Compute Capability: {compute_capability}\")\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")\n",
    "    \n",
    "    \n",
    "def epoch_S(mode, dataloader, net, optimizer, criterion, device, progress_bar):\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "    net = net.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    if mode == 'train':\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "    for i_batch, datum in enumerate(dataloader):\n",
    "        img = datum[0].float().to(device)\n",
    "        lab = datum[1].long().to(device)\n",
    "        n_b = lab.shape[0]\n",
    "\n",
    "        output = net(img)\n",
    "        loss = criterion(output, lab)\n",
    "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "\n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss.item() / (i + 1))\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg\n",
    "\n",
    "# function to get FLOPS for a given model\n",
    "def get_flops(model, dataloader, device):\n",
    "    for inputs, _ in dataloader:\n",
    "        # Get a single image from the batch\n",
    "        # add an extra batch dimension to the image, as the models expect a batch of\n",
    "        # images as input, not a single image.\n",
    "        single_image = inputs[0].unsqueeze(0).to(device)\n",
    "        break\n",
    "    flops = profile(model, inputs=(single_image, ), verbose=False)\n",
    "    return flops\n",
    "\n",
    "# function to get syn dataset from the output file\n",
    "def get_syn_dataset (sym_name):\n",
    "    syn_dataset_file = output_dir + sym_name\n",
    "    results = torch.load(syn_dataset_file, weights_only=True)\n",
    "    syn_imgs = results['data'][0][0]\n",
    "    syn_labels = results['data'][0][1]\n",
    "\n",
    "    syn_dataset = TensorDataset(syn_imgs, syn_labels)\n",
    "    channel = syn_imgs.shape[1]\n",
    "    num_classes = syn_labels.max().item() + 1\n",
    "    im_size = (syn_imgs.shape[2], syn_imgs.shape[3])\n",
    "    \n",
    "    dataloader = torch.utils.data.DataLoader(syn_dataset, batch_size=32, shuffle=True)\n",
    "    return syn_dataset, channel, num_classes, im_size, dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset from utils\n",
    "(\n",
    "    channel,\n",
    "    im_size,\n",
    "    num_classes,\n",
    "    class_names,\n",
    "    mean,\n",
    "    std,\n",
    "    train_MNIST_dataset,\n",
    "    test_MNIST_dataset,\n",
    "    test_MNIST_dataloader,\n",
    "    train_MNIST_dataloader,\n",
    ") = get_dataset(\"MNIST\", \"../datasets\")\n",
    "\n",
    "# visualize 10 classes of MNIST (2 by 5)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(\n",
    "        train_MNIST_dataset.data[train_MNIST_dataset.targets == i][0], cmap=\"gray\"\n",
    "    )\n",
    "    ax.set_title(f\"{i}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir + \"MNIST_dataset.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet3 = get_network('ConvNetD3', channel, num_classes, im_size)\n",
    "print(ConvNet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet3.parameters(), lr=lr)\n",
    "train_acc, test_acc = [], []\n",
    "trainLoader = train_MNIST_dataloader\n",
    "testLoader = test_MNIST_dataloader\n",
    "for ep in range (n_epochs):\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(trainLoader, 0),\n",
    "        total=len(trainLoader) + len(testLoader),\n",
    "        desc=f\"Epoch {ep+1}\",\n",
    "    )\n",
    "    \n",
    "    train_loss_avg, train_acc_avg = epoch_S('train', trainLoader, ConvNet3, optimizer, criterion, device, progress_bar)\n",
    "    test_loss_avg, test_acc_avg = epoch_S('test', testLoader, ConvNet3, optimizer, criterion, device,progress_bar)\n",
    "    \n",
    "    train_acc.append(train_acc_avg)\n",
    "    test_acc.append(test_acc_avg)\n",
    "\n",
    "ConvNet3_train_acc = train_acc\n",
    "ConvNet3_test_acc = test_acc\n",
    "\n",
    "flops, _ = get_flops(ConvNet3, testLoader, device)\n",
    "print(\"FLOPS: {:,}\".format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and test accuracy\n",
    "plt.plot(train_acc, label=\"Train\")\n",
    "plt.plot(test_acc, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'real',\n",
    "    '--model', 'ConvNetD3',\n",
    "    '--dataset', 'MNIST',\n",
    "    '--output_file', 'NMIST_real_res.pt',       # Output file\n",
    "    '--ipc', '10',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "NMIST_real_res = main_AttentionMatching.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "NMIST_real_res = output_dir + 'NMIST_real_res.pt'\n",
    "results = torch.load(NMIST_real_res)\n",
    "syn_imgs = results['data'][0][0]\n",
    "syn_imgs = torch.clamp(syn_imgs, 0, 1)\n",
    "\n",
    "# clip the images to [0, 1]\n",
    " \n",
    "# 10 images per class\n",
    "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(syn_imgs[i].permute(1, 2, 0).squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.suptitle(\"MNIST Synthetic Images\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'noise',\n",
    "    '--model', 'ConvNetD3',\n",
    "    '--dataset', 'MNIST',\n",
    "    '--output_file', 'NMIST_noise_res.pt',      # Output file\n",
    "    '--ipc', '10',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "NMIST_noise_res = main_AttentionMatching.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "NMIST_noise_res = output_dir + 'NMIST_noise_res.pt'\n",
    "results = torch.load(NMIST_noise_res, weights_only=True)\n",
    "syn_imgs = results['data'][0][0]\n",
    "syn_imgs = torch.clamp(syn_imgs, 0, 1)\n",
    "\n",
    "# clip the images to [0, 1]\n",
    " \n",
    "# 10 images per class\n",
    "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(syn_imgs[i].permute(1, 2, 0).squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "# figure title\n",
    "plt.suptitle(\"MNIST Synthesized Images (Noise Initialization)\", fontsize=16)\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet3 with Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_dataset, channel, num_classes, im_size, dataloader = get_syn_dataset('NMIST_real_res.pt')\n",
    "ConvNet3Syn = get_network('ConvNetD3', channel, num_classes, im_size)\n",
    "n_epochs = 20\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet3Syn.parameters(), lr=lr)\n",
    "train_acc, test_acc = [], []\n",
    "trainLoader = dataloader\n",
    "testLoader = test_MNIST_dataloader\n",
    "for ep in range (n_epochs):\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(trainLoader, 0),\n",
    "        total=len(trainLoader) + len(testLoader),\n",
    "        desc=f\"Epoch {ep+1}\",\n",
    "    )\n",
    "    \n",
    "    train_loss_avg, train_acc_avg = epoch_S('train', trainLoader, ConvNet3Syn, optimizer, criterion, device, progress_bar)\n",
    "    test_loss_avg, test_acc_avg = epoch_S('test', testLoader, ConvNet3Syn, optimizer, criterion, device,progress_bar)\n",
    "    \n",
    "    train_acc.append(train_acc_avg)\n",
    "    test_acc.append(test_acc_avg)\n",
    "    \n",
    "ConvNet3Syn_train_acc = train_acc\n",
    "ConvNet3Syn_test_acc = test_acc\n",
    "\n",
    "flops, _ = get_flops(ConvNet3Syn, testLoader, device)\n",
    "print(\"FLOPS: {:,}\".format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(7, 5))  # Set figure size\n",
    "\n",
    "# Plotting with different line styles for train (dashed) and test (solid) data\n",
    "plt.plot(ConvNet3_train_acc, label=\"Original Dataset [Train]\", linestyle='--', color='b')  # Dashed line for training\n",
    "plt.plot(ConvNet3_test_acc, label=\"Original Dataset [Test]\", linestyle='-', color='b')    # Solid line for testing\n",
    "plt.plot(ConvNet3Syn_train_acc, label=\"Synthetic Dataset [Train]\", linestyle='--', color='r')  # Dashed line for training\n",
    "plt.plot(ConvNet3Syn_test_acc, label=\"Synthetic Dataset [Test]\", linestyle='-', color='r')    # Solid line for testing\n",
    "\n",
    "# Add grid\n",
    "plt.grid(False)\n",
    "\n",
    "# Ensure x-axis displays only whole numbers, every 5 epochs\n",
    "plt.xticks(np.arange(0, n_epochs+1, 5))\n",
    "\n",
    "\n",
    "plt.xlabel(\"Epoch\", fontsize=12, fontweight='bold')\n",
    "plt.ylabel(\"Accuracy\", fontsize=12, fontweight='bold')\n",
    "plt.title(\"ConvNet3 Model Accuracy for MNIST Dataset\", fontsize=14, fontweight='bold')\n",
    "\n",
    "# Add legend with a better location\n",
    "plt.legend(loc='best', fontsize=10)\n",
    "\n",
    "# Add a tight layout to minimize unnecessary whitespace\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    channel,\n",
    "    im_size,\n",
    "    num_classes,\n",
    "    class_names,\n",
    "    mean,\n",
    "    std,\n",
    "    train_MHIST_dataset,\n",
    "    test_MHIST_dataset,\n",
    "    test_MHIST_dataloader,\n",
    "    train_MHIST_dataloader,\n",
    ") = get_dataset(\"MHIST\", \"../datasets\")\n",
    "\n",
    "indices = [100, 1560]\n",
    "\n",
    "# plot 2 images from the dataset\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_MHIST_dataset[indices[i]]\n",
    "    # Transpose the image from [3, 224, 224] to [224, 224, 3] for plotting\n",
    "    image = image.permute(1, 2, 0)\n",
    "    ax.imshow(image)\n",
    "    if label == 0:\n",
    "        ax.set_title(\"HP\")\n",
    "    else:\n",
    "        ax.set_title(\"SSA\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir + \"MHIST_dataset.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet7 = get_network('ConvNetD7', channel, num_classes, im_size)\n",
    "print(ConvNet7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet7.parameters(), lr=lr)\n",
    "train_acc, test_acc = [], []\n",
    "trainLoader = train_MHIST_dataloader\n",
    "testLoader = test_MHIST_dataloader\n",
    "for ep in range (n_epochs):\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(trainLoader, 0),\n",
    "        total=len(trainLoader) + len(testLoader),\n",
    "        desc=f\"Epoch {ep+1}\",\n",
    "    )\n",
    "    \n",
    "    train_loss_avg, train_acc_avg = epoch_S('train', trainLoader, ConvNet7, optimizer, criterion, device, progress_bar)\n",
    "    test_loss_avg, test_acc_avg = epoch_S('test', testLoader, ConvNet7, optimizer, criterion, device,progress_bar)\n",
    "    \n",
    "    train_acc.append(train_acc_avg)\n",
    "    test_acc.append(test_acc_avg)\n",
    "    \n",
    "flops, _ = get_flops(ConvNet7, testLoader, device)\n",
    "print(\"FLOPS: {:,}\".format(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'real',\n",
    "    '--model', 'ConvNetD7',\n",
    "    '--dataset', 'MHIST',\n",
    "    '--output_file', 'MHIST_real_res.pt',       # Output file\n",
    "    '--ipc', '50',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "MHIST_real_res = main_AttentionMatching.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHIST_real_res = output_dir + 'MHIST_real_res.pt'\n",
    "results = torch.load(MHIST_real_res, weights_only=True)\n",
    "syn_imgs = results['data'][0][0]\n",
    "syn_labels = results['data'][0][1]\n",
    "syn_imgs = torch.clamp(syn_imgs, 0, 1)\n",
    "\n",
    "# 50 images per class (HP, SSA)\n",
    "# create a grid of 50 images per class\n",
    "# create 1 image per class\n",
    "\n",
    "# label 0 is HP, label 1 is SSA\n",
    "HP_imgs = syn_imgs[syn_labels == 0]\n",
    "SSA_imgs = syn_imgs[syn_labels == 1]\n",
    "# plot only HP images\n",
    "fig, axes = plt.subplots(5, 10, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(HP_imgs[i].permute(1, 2, 0).squeeze())\n",
    "    ax.axis(\"off\")\n",
    "# figure title\n",
    "plt.suptitle(\"HP Synthesized Images\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plot only SSA images\n",
    "fig, axes = plt.subplots(5, 10, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(SSA_imgs[i].permute(1, 2, 0).squeeze())\n",
    "    ax.axis(\"off\")\n",
    "# figure title\n",
    "plt.suptitle(\"SSA Synthesized Images\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'noise',\n",
    "    '--model', 'ConvNetD7',\n",
    "    '--dataset', 'MHIST',\n",
    "    '--output_file', 'MHIST_noise_res.pt',      # Output file\n",
    "    '--ipc', '50',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "MHIST_noise_res = main_AttentionMatching.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MHIST_noise_res = output_dir + 'MHIST_noise_res.pt'\n",
    "results = torch.load(MHIST_noise_res, weights_only=True)\n",
    "syn_imgs = results['data'][0][0]\n",
    "syn_labels = results['data'][0][1]\n",
    "syn_imgs = torch.clamp(syn_imgs, 0, 1)\n",
    "\n",
    "# 50 images per class (HP, SSA)\n",
    "# create a grid of 50 images per class\n",
    "# create 1 image per class\n",
    "\n",
    "# label 0 is HP, label 1 is SSA\n",
    "HP_imgs = syn_imgs[syn_labels == 0]\n",
    "SSA_imgs = syn_imgs[syn_labels == 1]\n",
    "# plot only HP images\n",
    "fig, axes = plt.subplots(5, 10, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(HP_imgs[i].permute(1, 2, 0).squeeze())\n",
    "    ax.axis(\"off\")\n",
    "# figure title\n",
    "plt.suptitle(\"HP Synthesized Images (Noise Initialization)\", fontsize=16)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plot only SSA images\n",
    "fig, axes = plt.subplots(5, 10, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(SSA_imgs[i].permute(1, 2, 0).squeeze())\n",
    "    ax.axis(\"off\")\n",
    "# figure title\n",
    "plt.suptitle(\"SSA Synthesized Images (Noise Initialization)\", fontsize=16)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet7 with Synthetic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_dataset, channel, num_classes, im_size, dataloader = get_syn_dataset('MHIST_real_res.pt')\n",
    "ConvNet7Syn = get_network('ConvNetD7', channel, num_classes, im_size)\n",
    "n_epochs = 20\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet7Syn.parameters(), lr=lr)\n",
    "train_acc, test_acc = [], []\n",
    "trainLoader = dataloader\n",
    "testLoader = test_MNIST_dataloader\n",
    "for ep in range (n_epochs):\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(trainLoader, 0),\n",
    "        total=len(trainLoader) + len(testLoader),\n",
    "        desc=f\"Epoch {ep+1}\",\n",
    "    )\n",
    "    \n",
    "    train_loss_avg, train_acc_avg = epoch_S('train', trainLoader, ConvNet7Syn, optimizer, criterion, device, progress_bar)\n",
    "    test_loss_avg, test_acc_avg = epoch_S('test', testLoader, ConvNet7Syn, optimizer, criterion, device,progress_bar)\n",
    "    \n",
    "    train_acc.append(train_acc_avg)\n",
    "    test_acc.append(test_acc_avg)\n",
    "    \n",
    "ConvNet3Syn_train_acc = train_acc\n",
    "ConvNet3Syn_test_acc = test_acc\n",
    "\n",
    "flops, _ = get_flops(ConvNet7Syn, testLoader, device)\n",
    "print(\"FLOPS: {:,}\".format(flops)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
