{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "from torchvision.utils import save_image\n",
    "from thop import profile\n",
    "from utils import get_network, get_dataset\n",
    "import main_AttentionMatching\n",
    "import sys\n",
    "\n",
    "figures_dir = '../report/figures/'\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    device_name = torch.cuda.get_device_name(0)\n",
    "    properties = torch.cuda.get_device_properties(0)\n",
    "    compute_capability = f\"{properties.major}.{properties.minor}\"\n",
    "    total_memory = properties.total_memory / 1024**3\n",
    "\n",
    "    print(f\"CUDA Device: {device_name}\")\n",
    "    print(f\"CUDA Compute Capability: {compute_capability}\")\n",
    "    print(f\"Total Memory: {total_memory:.2f} GB\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"GPU is not available\")\n",
    "    \n",
    "    \n",
    "def epoch_S(mode, dataloader, net, optimizer, criterion, device, progress_bar):\n",
    "    loss_avg, acc_avg, num_exp = 0, 0, 0\n",
    "    net = net.to(device)\n",
    "    criterion = criterion.to(device)\n",
    "\n",
    "    if mode == 'train':\n",
    "        net.train()\n",
    "    else:\n",
    "        net.eval()\n",
    "\n",
    "    for i_batch, datum in enumerate(dataloader):\n",
    "        img = datum[0].float().to(device)\n",
    "        lab = datum[1].long().to(device)\n",
    "        n_b = lab.shape[0]\n",
    "\n",
    "        output = net(img)\n",
    "        loss = criterion(output, lab)\n",
    "        acc = np.sum(np.equal(np.argmax(output.cpu().data.numpy(), axis=-1), lab.cpu().data.numpy()))\n",
    "\n",
    "        loss_avg += loss.item()*n_b\n",
    "        acc_avg += acc\n",
    "        num_exp += n_b\n",
    "\n",
    "        if mode == 'train':\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        progress_bar.set_postfix(loss=loss.item() / (i + 1))\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    loss_avg /= num_exp\n",
    "    acc_avg /= num_exp\n",
    "\n",
    "    return loss_avg, acc_avg\n",
    "\n",
    "# function to get FLOPS for a given model\n",
    "def get_flops(model, dataloader, device):\n",
    "    for inputs, _ in dataloader:\n",
    "        # Get a single image from the batch\n",
    "        # add an extra batch dimension to the image, as the models expect a batch of\n",
    "        # images as input, not a single image.\n",
    "        single_image = inputs[0].unsqueeze(0).to(device)\n",
    "        break\n",
    "    flops = profile(model, inputs=(single_image, ), verbose=False)\n",
    "    return flops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset from utils\n",
    "(\n",
    "    channel,\n",
    "    im_size,\n",
    "    num_classes,\n",
    "    class_names,\n",
    "    mean,\n",
    "    std,\n",
    "    train_MNIST_dataset,\n",
    "    test_MNIST_dataset,\n",
    "    test_MNIST_dataloader,\n",
    "    train_MNIST_dataloader,\n",
    ") = get_dataset(\"MNIST\", \"../datasets\")\n",
    "\n",
    "# visualize 10 classes of MNIST (2 by 5)\n",
    "fig, axes = plt.subplots(2, 5, figsize=(10, 5))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(\n",
    "        train_MNIST_dataset.data[train_MNIST_dataset.targets == i][0], cmap=\"gray\"\n",
    "    )\n",
    "    ax.set_title(f\"{i}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir + \"MNIST_dataset.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet3 = get_network('ConvNetD3', channel, num_classes, im_size)\n",
    "print(ConvNet3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet3.parameters(), lr=lr)\n",
    "train_acc, test_acc = [], []\n",
    "trainLoader = train_MNIST_dataloader\n",
    "testLoader = test_MNIST_dataloader\n",
    "for ep in range (n_epochs):\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(trainLoader, 0),\n",
    "        total=len(trainLoader) + len(testLoader),\n",
    "        desc=f\"Epoch {ep+1}\",\n",
    "    )\n",
    "    \n",
    "    train_loss_avg, train_acc_avg = epoch_S('train', trainLoader, ConvNet3, optimizer, criterion, device, progress_bar)\n",
    "    test_loss_avg, test_acc_avg = epoch_S('test', testLoader, ConvNet3, optimizer, criterion, device,progress_bar)\n",
    "    \n",
    "    train_acc.append(train_acc_avg)\n",
    "    test_acc.append(test_acc_avg)\n",
    "    \n",
    "flops, _ = get_flops(ConvNet3, testLoader, device)\n",
    "print(\"FLOPS: {:,}\".format(flops))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the training and test accuracy\n",
    "plt.plot(train_acc, label=\"Train\")\n",
    "plt.plot(test_acc, label=\"Test\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'real',\n",
    "    '--model', 'ConvNetD3',\n",
    "    '--dataset', 'MNIST',\n",
    "    '--output_file', 'NMIST_real_res.pt',       # Output file\n",
    "    '--ipc', '10',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "NMIST_real_res = main_AttentionMatching.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "results = torch.load(NMIST_real_res)\n",
    "syn_imgs = results['data'][0][0]\n",
    "syn_imgs = torch.clamp(syn_imgs, 0, 1)\n",
    "\n",
    "# clip the images to [0, 1]\n",
    " \n",
    "# 10 images per class\n",
    "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(syn_imgs[i].permute(1, 2, 0).squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'noise',\n",
    "    '--model', 'ConvNetD3',\n",
    "    '--dataset', 'MNIST',\n",
    "    '--output_file', 'NMIST_noise_res.pt',      # Output file\n",
    "    '--ipc', '10',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "NMIST_noise_res = main_AttentionMatching.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the results\n",
    "results = torch.load(NMIST_noise_res)\n",
    "syn_imgs = results['data'][0][0]\n",
    "syn_imgs = torch.clamp(syn_imgs, 0, 1)\n",
    "\n",
    "# clip the images to [0, 1]\n",
    " \n",
    "# 10 images per class\n",
    "fig, axes = plt.subplots(10, 10, figsize=(10, 10))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    ax.imshow(syn_imgs[i].permute(1, 2, 0).squeeze(), cmap=\"gray\")\n",
    "    ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MHIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    channel,\n",
    "    im_size,\n",
    "    num_classes,\n",
    "    class_names,\n",
    "    mean,\n",
    "    std,\n",
    "    train_MHIST_dataset,\n",
    "    test_MHIST_dataset,\n",
    "    test_MHIST_dataloader,\n",
    "    train_MHIST_dataloader,\n",
    ") = get_dataset(\"MHIST\", \"../datasets\")\n",
    "\n",
    "indices = [100, 1560]\n",
    "\n",
    "# plot 2 images from the dataset\n",
    "fig, axes = plt.subplots(1, 2, figsize=(6, 3))\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    image, label = train_MHIST_dataset[indices[i]]\n",
    "    # Transpose the image from [3, 224, 224] to [224, 224, 3] for plotting\n",
    "    image = image.permute(1, 2, 0)\n",
    "    ax.imshow(image)\n",
    "    if label == 0:\n",
    "        ax.set_title(\"HP\")\n",
    "    else:\n",
    "        ax.set_title(\"SSA\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(figures_dir + \"MHIST_dataset.png\", dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ConvNet7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ConvNet7 = get_network('ConvNetD7', channel, num_classes, im_size)\n",
    "print(ConvNet7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 5\n",
    "lr = 0.01\n",
    "criterion = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(ConvNet7.parameters(), lr=lr)\n",
    "train_acc, test_acc = [], []\n",
    "trainLoader = train_MHIST_dataloader\n",
    "testLoader = test_MHIST_dataloader\n",
    "for ep in range (n_epochs):\n",
    "    progress_bar = tqdm(\n",
    "        enumerate(trainLoader, 0),\n",
    "        total=len(trainLoader) + len(testLoader),\n",
    "        desc=f\"Epoch {ep+1}\",\n",
    "    )\n",
    "    \n",
    "    train_loss_avg, train_acc_avg = epoch_S('train', trainLoader, ConvNet7, optimizer, criterion, device, progress_bar)\n",
    "    test_loss_avg, test_acc_avg = epoch_S('test', testLoader, ConvNet7, optimizer, criterion, device,progress_bar)\n",
    "    \n",
    "    train_acc.append(train_acc_avg)\n",
    "    test_acc.append(test_acc_avg)\n",
    "    \n",
    "flops, _ = get_flops(ConvNet7, testLoader, device)\n",
    "print(\"FLOPS: {:,}\".format(flops))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic dataset generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.argv = [\n",
    "    'main_AttentionMatching.py',\n",
    "    '--init', 'real',\n",
    "    '--model', 'ConvNetD7',\n",
    "    '--dataset', 'MHIST',\n",
    "    '--output_file', 'MHIST_real_res.pt',       # Output file\n",
    "    '--ipc', '50',                              # Images/class\n",
    "    '--lr_img', '0.1',                          # eta_s\n",
    "    '--lr_net', '0.01',                         # eta_theta\n",
    "    '--num_eval', '50',                         # zeta_theta\n",
    "    '--epoch_eval_train', '1',                  # zeta_s\n",
    "    '--Iteration', '10',                        # T\n",
    "]\n",
    "\n",
    "MHIST_real_res = main_AttentionMatching.main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
